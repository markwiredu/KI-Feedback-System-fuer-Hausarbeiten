"""
KI-Analysemodul f√ºr WriteWise - Hausarbeits-Feedback-System.

Dieses Modul implementiert eine KI-gest√ºtzte Analyse von Hausarbeiten unter Verwendung
von LangChain und OpenAI-kompatiblen LLMs. Es extrahiert strukturiertes Feedback
zu Sprache, Struktur und Argumentation.
"""

from dotenv import load_dotenv
from pydantic import BaseModel
from langchain_openai import ChatOpenAI
import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from typing import List, Optional

# ---------------------------
# Umgebungsvariablen und Datenmodelle
# ---------------------------

"""
L√§dt Umgebungsvariablen aus einer .env-Datei.

Diese Umgebungsvariablen werden typischerweise f√ºr API-Keys und Konfiguration
(OpenAI-kompatible Endpunkte) ben√∂tigt.
"""
load_dotenv()


class FeedbackResponse(BaseModel):
    """
    Pydantic-Modell f√ºr strukturiertes KI-Feedback.

    Dieses Modell definiert das strukturierte Ausgabeformat f√ºr die KI-Analyse,
    bestehend aus drei Feedback-Kategorien und einer optionalen Zusammenfassung.

    Attributes:
        language_feedback (List[str]):
            Feedback zu Sprache, Grammatik, Stil und Ausdruck.
            Jeder Eintrag sollte eine konkrete Textstelle referenzieren.

        structure_feedback (List[str]):
            Feedback zur Gliederung, Struktur und logischem Aufbau.
            Beinhaltet Verbesserungsvorschl√§ge f√ºr die Organisation.

        argumentation_feedback (List[str]):
            Feedback zur Argumentationslogik, Belegen und Schl√ºssigkeit.

        overall_summary (Optional[str]):
            Zusammenfassende Bewertung der gesamten Arbeit.
            Optionales Feld f√ºr abschlie√üende Einsch√§tzung.
    """

    language_feedback: List[str]
    structure_feedback: List[str]
    argumentation_feedback: List[str]
    overall_summary: Optional[str] = None


"""
Stellt sicher, dass das Pydantic-Modell korrekt initialisiert wird.

Dies kann notwendig sein, um Forward-Refs/Modelle korrekt aufzubauen und eine
konsistente Typvalidierung sowie Serialisierung sicherzustellen.
"""
FeedbackResponse.model_rebuild()

# ---------------------------
# Hauptanalysefunktion
# ---------------------------


def analyze_hausarbeit(text: str) -> dict:
    """
    Analysiert eine Hausarbeit mittels KI und generiert strukturiertes Feedback.

    Kernfunktion des Moduls, die ein Large Language Model (LLM) verwendet, um
    akademische Texte in mehreren Kategorien zu bewerten. Die Funktion kombiniert
    LangChain-Komponenten f√ºr Prompt-Engineering und strukturierte Ausgabe.

    Args:
        text (str):
            Der zu analysierende Text der Hausarbeit.
            Sollte bereits bereinigt und vorstrukturiert sein (z.B. mit Kapitel-/Seiten-Markierungen).

    Returns:
        dict: Strukturiertes Feedback-Dictionary mit folgenden Keys:
            - 'language_feedback' (List[str]): Sprachliche Verbesserungsvorschl√§ge
            - 'structure_feedback' (List[str]): Strukturelle Hinweise
            - 'argumentation_feedback' (List[str]): Argumentations-Feedback
            - 'overall_summary' (Optional[str]): Gesamteinsch√§tzung

    Raises:
        Exception:
            Bei Fehlern in der KI-Verarbeitung wird der Fehler geloggt und
            konsistentes Fallback-Feedback zur√ºckgegeben.

    Workflow:
        1. Initialisierung des LLM mit Konfiguration aus .env
        2. Erstellung eines strukturierten Output-Parsers (Pydantic)
        3. Definition des Prompt-Templates (System- und Human-Prompt)
        4. Ausf√ºhrung der Analyse-Kette (Prompt ‚Üí LLM ‚Üí Parser)
        5. Umwandlung in Dictionary-Format

    Example:
        >>> feedback = analyze_hausarbeit("In dieser Arbeit untersuche ich...")
        >>> print(feedback["structure_feedback"])
        ["Die Einleitung k√∂nnte pr√§gnanter formuliert werden..."]

    Notes:
        - Verwendet OpenAI-kompatible APIs (via base_url Konfiguration).
        - Ber√ºcksichtigt m√∂gliche Extraktionsartefakte bei der Analyse.
        - Liefert konstruktives, motivierendes Feedback.
    """
    # ---------------------------
    # LLM Initialisierung
    # ---------------------------

    """
    Initialisiert das ChatOpenAI-Modell mit benutzerdefinierter Konfiguration.

    Configuration:
        model (str):
            "chat-default" als Standard-Chat-Modell.
        base_url (str | None):
            Wert aus der Umgebungsvariable OPENAI_BASE_URL.
        api_key (str | None):
            Wert aus der Umgebungsvariable OPENAI_API_KEY.

    Note:
        Der base_url-Parameter erm√∂glicht die Nutzung von OpenAI-kompatiblen APIs,
        z.B. lokalen LLM-Servern oder alternativen Anbietern.
    """
    llm = ChatOpenAI(
        model="chat-default",
        base_url=os.getenv("OPENAI_BASE_URL"),
        api_key=os.getenv("OPENAI_API_KEY"),
    )

    # ---------------------------
    # Output-Parser Initialisierung
    # ---------------------------

    """
    Erstellt einen Parser f√ºr strukturierte Ausgaben.

    Wandelt die LLM-Antwort in das definierte FeedbackResponse-Modell um.
    Dies erzwingt eine konsistente Ausgabestruktur und erm√∂glicht Typvalidierung.
    """
    parser = PydanticOutputParser(pydantic_object=FeedbackResponse)

    # ---------------------------
    # Prompt-Template Definition
    # ---------------------------

    """
    Definiert das zweiteilige Prompt-Template f√ºr die KI-Analyse.

    Struktur:
        1) System-Prompt:
           Rolle, Aufgabenstellung, Regeln und Formatierungsanweisungen.
        2) Human-Prompt:
           Platzhalter f√ºr den tats√§chlichen Hausarbeitstext.

    System-Prompt enth√§lt u.a.:
        - Rollendefinition (akademischer Assistent)
        - Analysebereiche (Struktur, Argumentation, Inhalt, Sprache)
        - Einschr√§nkungen (Extraktionsartefakte ber√ºcksichtigen)
        - Feedback-Stilrichtlinien (konstruktiv, sachlich, motivierend)
        - Ausgabeformat via format_instructions

    Human-Prompt:
        {query}: Wird mit dem tats√§chlichen Text der Hausarbeit bef√ºllt.
    """
    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """
                Du bist ein akademischer Assistent, der schriftliche Hausarbeiten analysiert
                und konstruktives, fachlich korrektes Feedback gibt.

                Ziel deiner Analyse ist es, Studierenden bei der inhaltlichen und sprachlichen
                Verbesserung ihrer Arbeit zu helfen. Beurteile ausschlie√ülich den vorliegenden Text.

                Analysiere die Arbeit in folgenden Bereichen:

                1. Struktur:
                   - Aufbau von Einleitung, Hauptteil und Schluss
                   - logische Gliederung und Nachvollziehbarkeit
                   - roter Faden und √úberg√§nge zwischen Abschnitten

                2. Argumentation:
                   - Klarheit und Schl√ºssigkeit der Argumente
                   - Begr√ºndungen, Beispiele und Folgerungen
                   - innere Logik und Konsistenz

                3. Inhalt:
                   - thematische Relevanz
                   - inhaltliche Tiefe und Pr√§zision
                   - sachliche Angemessenheit (ohne Fakten zu erfinden oder zu √ºberpr√ºfen)

                4. Sprache und Stil:
                   - Verst√§ndlichkeit und Lesefluss
                   - akademischer Stil und Ausdruck
                   - Wortwahl und Satzstruktur

                Wichtige Einschr√§nkungen und Regeln:
                - Der Text kann aus einer Datei (z. B. PDF oder DOCX) stammen und automatisch extrahiert worden sein.
                - Kritisiere daher keine m√∂glichen Fehler bei Leerzeichen, Worttrennungen, Interpunktion
                  oder offensichtliche Formatierungsartefakte, wenn diese plausibel technisch bedingt sind.
                - Gib keine Rechtschreib- oder Grammatikhinweise, die eindeutig auf Dateiextraktion
                  oder automatische Textverarbeitung zur√ºckzuf√ºhren sein k√∂nnten.
                - Verweise bei Kritik oder Verbesserungsvorschl√§gen m√∂glichst pr√§zise auf Textstellen,
                  z. B. durch Absatzinhalt, Satzanfang oder inhaltliche Beschreibung,
                  jedoch nur, sofern dies anhand des gegebenen Textes zuverl√§ssig m√∂glich ist.
                - Erfinde keine Seitenzahlen, Abs√§tze oder Textstellen.

                Feedback-Stil:
                - Beginne jede Kategorie mit mindestens einem positiven Aspekt.
                - Formuliere konstruktiv, sachlich und motivierend.
                - Keine pauschalen Urteile, sondern konkrete, nachvollziehbare Hinweise.
                - Antworte ausschlie√ülich bezogen auf den eingegebenen Text.
                - Jeder Feedbackpunkt soll maximal 2‚Äì3 S√§tze enthalten.

                Gib dein Feedback ausschlie√ülich im vorgegebenen strukturierten Ausgabeformat aus.

                {format_instructions}
                """,
            ),
            ("human", "{query}"),
        ]
    ).partial(format_instructions=parser.get_format_instructions())

    # ---------------------------
    # Analyse-Kette aufbauen
    # ---------------------------

    """
    Kombiniert die Komponenten zu einer Verarbeitungskette.

    Chain sequence:
        1) Prompt: Wendet das Template auf Input an
        2) LLM: Verarbeitet den formatierten Prompt
        3) Parser: Konvertiert die LLM-Antwort in ein strukturiertes Pydantic-Modell

    Pipeline:
        Input ‚Üí Prompt Template ‚Üí LLM ‚Üí Parser ‚Üí Strukturierte Ausgabe
    """
    chain = prompt | llm | parser

    try:
        # ---------------------------
        # Ausf√ºhrung der Analyse
        # ---------------------------

        """
        F√ºhrt die Analyse-Kette mit dem bereitgestellten Text aus.

        Prozess:
            1) Verpackt den Text in ein Dictionary unter dem Key "query"
            2) √úbergibt an die LangChain-Pipeline
            3) Erh√§lt ein FeedbackResponse-Objekt

        Error handling:
            Fehler werden als Exception ausgel√∂st und im except-Block behandelt.
        """
        response = chain.invoke({"query": text})

        # ---------------------------
        # Umwandlung und R√ºckgabe
        # ---------------------------

        """
        Konvertiert das Pydantic-Modell in ein Python-Dictionary.

        Dadurch wird JSON-Serialisierung erleichtert und Kompatibilit√§t mit
        anderen Systemkomponenten (z.B. Flask-API) sichergestellt.
        """
        return {
            "language_feedback": response.language_feedback,
            "structure_feedback": response.structure_feedback,
            "argumentation_feedback": response.argumentation_feedback,
            "overall_summary": response.overall_summary,
        }

    except Exception as e:
        """
        Fehlerbehandlung bei gescheiterter KI-Analyse.

        Loggt den Fehler und gibt konsistentes Fallback-Feedback zur√ºck,
        um Systemstabilit√§t zu gew√§hrleisten.

        Fallback-Feedback:
            - Enth√§lt Fehlermeldung in language_feedback
            - Leere Listen f√ºr andere Kategorien
            - Klare Fehlerkennzeichnung in overall_summary
        """
        print(f"‚ùå Fehler bei KI-Analyse: {e}")
        return {
            "language_feedback": [f"Analyse fehlgeschlagen: {str(e)}"],
            "structure_feedback": [],
            "argumentation_feedback": [],
            "overall_summary": "Fehler bei der Analyse",
        }


# ---------------------------
# Test- und Entwicklungsbereich
# ---------------------------

if __name__ == "__main__":
    """
    Entwicklungs-/Integrationstest f√ºr die Analysefunktion.

    Wird nur ausgef√ºhrt, wenn das Modul direkt gestartet wird (nicht bei Import).
    Dient zur Verifikation der grundlegenden Funktionalit√§t und als Beispiel
    f√ºr die Verwendung.

    Test case:
        - Kurzer Beispieltext zum Klimawandel
        - Ausgabe aller Feedback-Kategorien
    """
    test_text = """
    In dieser Hausarbeit werde ich die Auswirkungen des Klimawandels auf die Landwirtschaft in Deutschland untersuchen. 
    Der Klimawandel ist ein wichtiges Thema und betrifft uns alle. Die Landwirtschaft muss sich anpassen 
    und neue Methoden finden. Es gibt viele Studien dazu, die verschiedene Aspekte beleuchten.
    """

    print("üß™ Teste KI-Analyse...")
    result = analyze_hausarbeit(test_text)
    print("‚úÖ Analyse erfolgreich!")
    print(f"Sprache: {result['language_feedback']}")
    print(f"Struktur: {result['structure_feedback']}")
    print(f"Argumentation: {result['argumentation_feedback']}")
    print(f"Zusammenfassung: {result['overall_summary']}")
